{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66f3f6f",
   "metadata": {},
   "source": [
    "# Kontrol Mouse dengan Pelacakan Gerakan Tangan\n",
    "\n",
    "**Zufar Syaafi'**  \n",
    "<zufar.syaafie@gmail.com>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536f2d5",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <video width=\"640\" controls>\n",
    "        <source src=\"image/demo.mp4\" type=\"video/mp4\">\n",
    "        Your browser does not support the video tag.\n",
    "    </video>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cbb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1.0\n",
    "# python version: 3.10.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5faacad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment the following line to install the required packages\n",
    "# !pip install cv2 mediapipe pyautogui pynput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aeaf70",
   "metadata": {},
   "source": [
    "## 1. Pendahuluan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405881f6",
   "metadata": {},
   "source": [
    "### 1.1 Latar Belakang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb3e65",
   "metadata": {},
   "source": [
    "Interaksi manusia dengan komputer pada umumnya dilakukan dengan perantara perangkat input fisik berupa _mouse_ dan _keyyboard_. Namun, apa jadinya jika interaksi itu diimplementasikan dengan metode alternatif yang lebih intuitif berupa gerakan tangan langsung?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f957f",
   "metadata": {},
   "source": [
    "### 1.2 Tujuan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb38c9e",
   "metadata": {},
   "source": [
    "Tujuan utama dari proyek ini adalah untuk membagun sebuah program dengan kemampuan sebagai berikut.\n",
    "1. Mengakses _feed_ video dari _webcam_\n",
    "2. Mendetksi dan melacak tangan sekaligus jari-jarinya\n",
    "3. Mengenalis gestur tertentu\n",
    "4. Menerjemahkan gestur menjadi aksi kontrol mouse tertentu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7bd94",
   "metadata": {},
   "source": [
    "## 2. Komponen dan Pustaka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a616a",
   "metadata": {},
   "source": [
    "Proyek ini menggunakan beberapa pustaka python, yaitu\n",
    "1. OpenCV (`cv2`): Untuk melakukan _image capturing_ dan _processing_ dari video _webcam_\n",
    "2. MediaPipe (`mediapipe`): Untuk meng-_handle_ deteksi tangan dan ekstraksi 21 _landmark_ dari tangan yang terdeteksi\n",
    "3. PyAutoGUI & Pynput: Untuk mengerjakan tugas kontrol mouse secara terprogram\n",
    "4. NumPy: Untuk membantu melakukan kalkulasi matematis, terutama untuk menghitung jarak dan sudut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f1f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from pynput.mouse import Button, Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebdfbf",
   "metadata": {},
   "source": [
    "## 3. Metodologi dan Cara Kerja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87de81",
   "metadata": {},
   "source": [
    "### 3.1 Gestur Tangan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043426b5",
   "metadata": {},
   "source": [
    "Pengolahan gestur tangan dimulai dengan memberikan 21 _landmark_ untuk telapak tangan. Proyek ini menggunakan standar _landmark_ dari MediaPipe sebagai berikut.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://mediapipe.dev/images/mobile/hand_landmarks.png\" alt=\"hand_landmarks.png\" />\n",
    "    <p><em>Gambar 1. 21 landmarks tangan.</em></p>\n",
    "</div>\n",
    "\n",
    "Adapun gestur yang akan digunakan adalah kondisi-kondisi khusus dari posisi _landmarks_ yang masing-masing secara berurutan mewakili aksi _move_ (memindahkan kursor), stop, klik kiri, klik kanan, klik kanan ganda, dan mengambil tangkapan layar. Lebih detail ada pada _Gambar 2._\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td align=\"center\"><img src=\"image/move.png\" alt=\"move.png\" /><br><em>Gambar 2.1 Gestur move.</em></td>\n",
    "            <td align=\"center\"><img src=\"image/stop.png\" alt=\"stop.png\" /><br><em>Gambar 2.2 Gestur stop.</em></td>\n",
    "            <td align=\"center\"><img src=\"image/lb.png\" alt=\"lb.png\" /><br><em>Gambar 2.3 Gestur klik kiri.</em></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td align=\"center\"><img src=\"image/rb.png\" alt=\"rb.png\" /><br><em>Gambar 2.4 Gestur klik kanan.</em></td>\n",
    "            <td align=\"center\"><img src=\"image/double.png\" alt=\"double.png\" /><br><em>Gambar 2.5 Gestur klik kanan ganda.</em></td>\n",
    "            <td align=\"center\"><img src=\"image/ss.png\" alt=\"ss.png\" /><br><em>Gambar 2.6 Gestur screenshot.</em></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <p><em>Gambar 2. Gestur tangan.</em></p>\n",
    "</div>\n",
    "\n",
    "Semua gestur pada _Gambar 2._ memiliki aksi statis, kecuali gestur _move_ pada _Gambar 2.1_. Gestur move akan melacak posisi _landmark_ paling ujung dari jari telunjuk (`INDEX_FINGER_TIP`/8) untuk dijadikan posisi kursor di layar komputer. Jadi, kursor akan bergeser mengikuti pergeseran dari _landmark_ terkait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc12714",
   "metadata": {},
   "source": [
    "### 3.2 Perhitungan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e049e0",
   "metadata": {},
   "source": [
    "Untuk memastikan _mouse_ \"virtual\" berfungsi diperlukan cara untuk mengidentifikasi kapan jari ditekuk atau diluruskan, atau seberapa dekat satu jari dengan jari lainnya. Proses identifikasi itu bisa dilakukan dengan melakukan perhitungan jarak dan sudut. Ada dua pola utama dalam gestur pada _Gambar 2._. Pertama, ibu jari yang membuka dan menutup. Ini berarti kita menghitung jarak antara titik ujung ibu jari dengan titik akhir dari jari telunjuk atau jarak antara _landmark_ 4 dan 5 (lihat _Gambar 3.1_). Kedua, jari telunjuk atau tengah yang lurus atau menekuk. Ini bisa ditentukan dengan menghitung seberapa besar sudut yang tebentuk antara garis diatas titik tekuk dan dibawah titik tekuk (lihat _Gambar 3.2_).\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td align=\"center\">\n",
    "                <img src=\"image/jarak.png\" alt=\"jarak.png\" width=\"250\"><br>\n",
    "                <em>Gambar 3.1 Jarak antara dua titik.</em>\n",
    "            </td>\n",
    "            <td align=\"center\">\n",
    "                <img src=\"image/sudut.png\" alt=\"sudut.png\" width=\"250\"><br>\n",
    "                <em>Gambar 3.2 Sudut antara dua garis.</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <p><em>Gambar 3. Konsep jarak dan sudut.</em></p>\n",
    "</div>\n",
    "\n",
    "Untuk menentukan jarak antara dua titik kita bisa lakukan dengan menggunakan persamaan jarak euclidian sebagai berikut.\n",
    "$$\n",
    "\\text{jarak} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
    "$$\n",
    "Jadi, misalkan ada dua titik $P_1 = (x_1, y_1)$, dan $P_2 = (x_2, y_2)$, jarak antara dua titik itu bisa dihitung dengan persamaan diatas. Jika hasil jarak kecil, itu artinya ibu jari mendekat ke telunjuk. Berikut implementasi dalam fungsi python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02dd066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_points(p1, p2):\n",
    "    \"\"\"Calculate the distance between two points.\"\"\"\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33702aab",
   "metadata": {},
   "source": [
    "Adapun untuk menentukan sudut yang terbentuk antara dua garis seperti yang sudah dijelaskan, dapat dilakukan operasi sebagai berikut.\n",
    "$$\n",
    "\\theta = \\cos^{-1}\\left( \\frac{\\vec{BA} \\cdot \\vec{BC}}{\\lVert \\vec{BA} \\rVert \\cdot \\lVert \\vec{BC} \\rVert} \\right)\n",
    "$$\n",
    "Jadi, misalkan diketahui titik-titik:  \n",
    "  - $A = \\text{titik atas}$  \n",
    "  - $B = \\text{titik tekuk}$  \n",
    "  - $C = \\text{titik bawah}$\n",
    "\n",
    "sudut akan dihitung di titik $B$ menggunakan persamaan di atas. Apabila sudut mendekati 180° dapat disimpulkan jari lurus. Namun, apabila sudut mendekati 90° dapat dikatakan bahwa jari sedang menekuk. Berikut implementasi dalam fungsi python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cda00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between_points(p1, p2, p3):\n",
    "    \"\"\"Calculate the angle between three points.\"\"\"\n",
    "    v1 = np.array(p1) - np.array(p2)\n",
    "    v2 = np.array(p3) - np.array(p2)\n",
    "    v1_norm = np.linalg.norm(v1)\n",
    "    v2_norm = np.linalg.norm(v2)\n",
    "\n",
    "    if v1_norm == 0 or v2_norm == 0:\n",
    "        return 0\n",
    "    cos_angle = np.degrees(np.arccos\n",
    "                           (np.clip\n",
    "                            (np.dot(v1, v2) / (v1_norm * v2_norm), -1.0, 1.0)))\n",
    "    return cos_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b37954",
   "metadata": {},
   "source": [
    "### 3.3 Implementsi Proses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9917c959",
   "metadata": {},
   "source": [
    "#### 3.3.1 Inisialisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1a777",
   "metadata": {},
   "source": [
    "Pada tahap ini, semua komponen yang diperlukan untuk fungsionalitas _mouse_ virtual disiapkan. Pertama, koneksi ke _webcam_ diaktifkan melalui perintah `cv2.VideoCapture(0)` untuk menangkap input visual secara _real-time_. Selanjutnya, model `Hands` dari MediaPipe diinisialisasi dengan konfigurasi untuk mendeteksi satu tangan, diatur dengan tingkat kepercayaan deteksi dan pelacakan yang tinggi untuk memastikan akurasi. Terakhir, untuk menerjemahkan gerakan tangan menjadi gerakan kursor, ukuran layar dideteksi menggunakan `pyautogui.size()`, sementara modul kontroler dari `pynput` digunakan untuk mengendalikan _mouse_ secara virtual di seluruh sistem operasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a5203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pyautogui to fail-safe mode\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "# Mouse controller\n",
    "mouse = Controller()\n",
    "\n",
    "# Initialize screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.8,\n",
    "    min_tracking_confidence=0.8,\n",
    "    model_complexity=1\n",
    ")\n",
    "\n",
    "draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b0914",
   "metadata": {},
   "source": [
    "#### 3.3.2 Operasional Gerakan _Mouse_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5c585",
   "metadata": {},
   "source": [
    "Pada tahap ini program berpusat pada dua fungsi utama untuk menerjemahkan gerakan menjadi aksi. Pertama, fungsi `find_finger_tip(result)` berperan sebagai pencari data yang memeriksa hasil pemrosesan dari MediaPipe. Jika sebuah tangan terdeteksi, fungsi ini akan mengekstrak dan mengembalikan lokasi _landmark_ dari ujung jari telunjuk (`INDEX_FINGER_TIP`/8), yang bertindak sebagai titik acuan untuk kursor. Kemudian, jika titik acuan ini berhasil ditemukan, fungsi `move_mouse(finger_tip)` mengambil alih tugas sebagai eksekutor. Fungsi ini mengubah koordinat relatif (nilai 0.0 hingga 1.0) dari ujung jari menjadi koordinat piksel absolut pada layar, sekaligus menerapkan faktor sensitivitas untuk membuat gerakan terasa lebih luas dan nyaman. Terakhir, perintah `pyautogui.moveTo(x, y)` akan dieksekusi untuk memindahkan kursor _mouse_ secara asli di layar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25296284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_finger_tip(result):\n",
    "    if result.multi_hand_landmarks:\n",
    "        hand_landmarks = result.multi_hand_landmarks[0]\n",
    "        return hand_landmarks.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    return None\n",
    "\n",
    "\n",
    "def move_mouse(finger_tip):\n",
    "    if finger_tip:\n",
    "        x = int(finger_tip.x * screen_width * 1.5)\n",
    "        y = int(finger_tip.y * screen_height * 1.5)\n",
    "        pyautogui.moveTo(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ae7bb",
   "metadata": {},
   "source": [
    "#### 3.3.3 Kondisi Aksi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41357b1",
   "metadata": {},
   "source": [
    "Bagian ini menjelaskan logika dari setiap aksi yang dipicu berdasarkan kombinasi antara sudut antar sendi jari dan jarak antara ibu jari dan jari telunjuk (`thumb_dist`). Penggunaan sudut membantu mendeteksi apakah jari dalam keadaan lurus atau menekuk, sementara jarak antara ibu jari dan telunjuk menjadi indikator untuk gestur membuka atau menutup.\n",
    "\n",
    "Fungsi `is_move_mouse(...)` mengidentifikasi kondisi untuk menggerakkan kursor. Aksi ini dipicu ketika jari telunjuk berada dalam kondisi lurus (sudut antara titik 5-6-8 lebih dari 90 derajat), dan ibu jari dalam keadaan menutup ke arah telunjuk (jarak antara titik 4 dan 5 kurang dari 10). Kombinasi ini biasanya terjadi ketika pengguna menunjuk lurus sambil menutup ibu jari, meniru gerakan natural mengarahkan kursor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17636361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_move_mouse(list_landmarks, thumb_dist):\n",
    "    return (\n",
    "        angle_between_points(list_landmarks[5], list_landmarks[6], list_landmarks[8])\n",
    "        > 90\n",
    "        and thumb_dist < 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487230f",
   "metadata": {},
   "source": [
    "Fungsi `is_left_click(...)` digunakan untuk mendeteksi klik kiri. Syaratnya adalah jari telunjuk menekuk (sudut < 90°), jari tengah lurus (sudut > 90°), dan ibu jari membuka (jarak > 10). Posisi ini menyerupai gestur menekan tombol menggunakan telunjuk sementara jari tengah tetap lurus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2715cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_left_click(list_landmarks, thumb_dist):\n",
    "    return (\n",
    "        angle_between_points(list_landmarks[5], list_landmarks[6], list_landmarks[8])\n",
    "        < 90\n",
    "        and angle_between_points(\n",
    "            list_landmarks[12], list_landmarks[10], list_landmarks[9]\n",
    "        )\n",
    "        > 90\n",
    "        and thumb_dist > 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a9bca",
   "metadata": {},
   "source": [
    "Fungsi `is_right_click(...)` akan mengembalikan nilai benar jika jari telunjuk lurus (sudut > 90°), jari tengah menekuk (sudut < 90°), dan ibu jari membuka (jarak > 10). Kombinasi ini menunjukkan bahwa pengguna menggunakan jari tengah untuk memberi sinyal klik, dengan telunjuk tetap lurus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1f5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_right_click(list_landmarks, thumb_dist):\n",
    "    return (\n",
    "        angle_between_points(list_landmarks[5], list_landmarks[6], list_landmarks[8])\n",
    "        > 90\n",
    "        and angle_between_points(\n",
    "            list_landmarks[12], list_landmarks[10], list_landmarks[9]\n",
    "        )\n",
    "        < 90\n",
    "        and thumb_dist > 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e5cb8",
   "metadata": {},
   "source": [
    "Fungsi `is_double_click(...)` mendeteksi klik ganda. Syaratnya adalah baik jari telunjuk maupun jari tengah berada dalam kondisi menekuk (sudut < 90°) dan ibu jari membuka (jarak > 10). Ini menyerupai gestur menekan dua kali cepat menggunakan telunjuk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7400a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_double_click(list_landmarks, thumb_dist):\n",
    "    return(\n",
    "        angle_between_points(\n",
    "            list_landmarks[5],\n",
    "            list_landmarks[6],\n",
    "            list_landmarks[8]) < 90 and\n",
    "        angle_between_points(\n",
    "            list_landmarks[12],\n",
    "            list_landmarks[10],\n",
    "            list_landmarks[9]) < 90 and\n",
    "        thumb_dist > 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d32c6",
   "metadata": {},
   "source": [
    "Fungsi `is_screenshot(...)` mengembalikan nilai benar jika kedua jari (telunjuk dan tengah) menekuk (sudut < 90°) dan ibu jari dalam posisi menutup (jarak < 10). Gestur ini bisa diinterpretasikan sebagai tanda menutup atau menggenggam yang bisa digunakan sebagai pemicu pengambilan tangkapan layar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750c809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_screenshot(list_landmarks, thumb_dist):\n",
    "    return (\n",
    "        angle_between_points(list_landmarks[5], list_landmarks[6], list_landmarks[8])\n",
    "        < 90\n",
    "        and angle_between_points(\n",
    "            list_landmarks[12], list_landmarks[10], list_landmarks[9]\n",
    "        )\n",
    "        < 90\n",
    "        and thumb_dist < 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caffac1",
   "metadata": {},
   "source": [
    "### 3.3.4 Deteksi Gestur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f0637",
   "metadata": {},
   "source": [
    "Fungsi `detect_gesture(...)` bertanggung jawab untuk mengenali gestur tangan berdasarkan landmark jari yang terdeteksi, lalu menjalankan aksi tertentu seperti menggerakkan kursor, melakukan klik, atau mengambil tangkapan layar. Proses ini dilakukan secara real-time dengan mengambil input berupa `frame` dari kamera, daftar `list_landmarks`, dan hasil pendeteksian dari model.\n",
    "\n",
    "Langkah pertama dalam fungsi ini adalah memeriksa apakah jumlah landmark yang terdeteksi cukup (minimal 21 titik). Selanjutnya, sistem mencari koordinat ujung jari telunjuk (`index_finger_tip`) menggunakan fungsi `find_finger_tip(...)` dan menghitung jarak antara ibu jari dan pangkal jari telunjuk (`thumb_dist`) menggunakan fungsi `distance_between_points(...)`.\n",
    "\n",
    "Setelah informasi jarak dan posisi terkumpul, sistem akan memeriksa satu per satu kondisi gestur:\n",
    "\n",
    "- Jika kondisi `is_move_mouse(...)` terpenuhi (telunjuk lurus dan ibu jari menutup), maka kursor akan digerakkan ke posisi ujung jari telunjuk.\n",
    "- Jika `is_left_click(...)` terpenuhi (telunjuk menekuk, tengah lurus, ibu jari membuka), maka sistem melakukan klik kiri dan menampilkan teks \"Left Click\" di layar.\n",
    "- Jika `is_right_click(...)` terpenuhi (telunjuk lurus, tengah menekuk, ibu jari membuka), maka sistem melakukan klik kanan dan menampilkan \"Right Click\".\n",
    "- Jika `is_double_click(...)` aktif (telunjuk dan tengah menekuk, ibu jari membuka), maka sistem melakukan klik ganda.\n",
    "- Jika `is_screenshot(...)` aktif (telunjuk dan tengah menekuk, ibu jari menutup), maka sistem mengambil tangkapan layar dan menyimpannya sebagai file `\"screenshot.png\"`.\n",
    "\n",
    "Setiap aksi juga disertai teks indikator yang ditampilkan di sudut atas frame menggunakan `cv2.putText(...)`, dengan warna yang berbeda-beda untuk membedakan jenis aksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ffaa697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_gesture(frame, list_landmarks, result):\n",
    "    if len(list_landmarks) >= 21:\n",
    "        index_finger_tip = find_finger_tip(result)\n",
    "        thumb_dist = distance_between_points(list_landmarks[4], list_landmarks[5])\n",
    "\n",
    "        if is_move_mouse(list_landmarks, thumb_dist):\n",
    "            move_mouse(index_finger_tip)\n",
    "            cv2.putText(frame, \"Move Mouse\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        elif is_left_click(list_landmarks, thumb_dist):\n",
    "            mouse.click(Button.left, 1)\n",
    "            # add a small delay to allow the system to process\n",
    "            cv2.waitKey(500)\n",
    "            cv2.putText(frame, \"Left Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        elif is_right_click(list_landmarks, thumb_dist):\n",
    "            mouse.click(Button.right, 1)\n",
    "            # add a small delay to allow the system to process\n",
    "            cv2.waitKey(500)\n",
    "            cv2.putText(frame, \"Right Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        elif is_double_click(list_landmarks, thumb_dist):\n",
    "            mouse.click(Button.left, 2)\n",
    "            # add a small delay to allow the system to process\n",
    "            cv2.waitKey(500)\n",
    "            cv2.putText(frame, \"Double Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "        elif is_screenshot(list_landmarks, thumb_dist):\n",
    "            screenshot = pyautogui.screenshot()\n",
    "            screenshot.save(\"screenshot.png\")\n",
    "            cv2.putText(frame, \"Screenshot Taken\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb125c3",
   "metadata": {},
   "source": [
    "#### 3.3.5 Pengambilan dan Pemrosesan Video Kamera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f88c4",
   "metadata": {},
   "source": [
    "Fungsi `camera()` merupakan komponen utama untuk mengakses _webcam_, memproses citra tangan secara _real-time_, dan menjalankan deteksi gestur yang telah didefinisikan sebelumnya.\n",
    "\n",
    "Pertama, kamera diakses menggunakan `cv2.VideoCapture(0)` yang membuka perangkat kamera utama (biasanya webcam). Proses pembacaan frame dilakukan secara terus-menerus selama kamera terbuka. Setiap frame akan dibalik secara horizontal menggunakan `cv2.flip(frame, 1)` agar sesuai dengan orientasi gerakan pengguna (efek cermin), lalu dikonversi dari format BGR ke RGB agar dapat diproses oleh MediaPipe Hands.\n",
    "\n",
    "Selanjutnya, sistem mempersiapkan list kosong `list_landmarks` untuk menyimpan koordinat dari titik-titik landmark tangan yang terdeteksi. Kemudian, citra RGB diproses oleh `hands.process(...)` dari MediaPipe. Jika tangan berhasil dideteksi, maka landmark tangan pertama (`multi_hand_landmarks[0]`) akan digambar pada frame menggunakan `draw.draw_landmarks(...)`, dan setiap titik landmark (berupa nilai `x` dan `y`) akan disimpan dalam `list_landmarks`.\n",
    "\n",
    "Fungsi `detect_gesture(...)` kemudian dipanggil, mengirimkan frame saat ini, daftar landmark, dan hasil deteksi sebagai argumen, untuk menentukan apakah ada gestur tertentu yang dikenali (seperti klik, gerak mouse, screenshot, dll).\n",
    "\n",
    "Akhirnya, frame yang sudah diproses ditampilkan melalui `cv2.imshow(...)`. Pengguna bisa keluar dari aplikasi dengan menekan tombol `Esc`. Saat keluar, kamera dan semua jendela OpenCV ditutup dengan aman menggunakan `cap.release()` dan `cv2.destroyAllWindows()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e23f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    try: \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "            \n",
    "            # Convert the BGR image to RGB\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # List to hold hand landmarks\n",
    "            list_landmarks = []\n",
    "\n",
    "            # Process the frame with MediaPipe Hands\n",
    "            results = hands.process(rgb_frame)\n",
    "            if results.multi_hand_landmarks:\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                draw.draw_landmarks(frame, hand_landmarks, mpHands.HAND_CONNECTIONS)\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    list_landmarks.append((landmark.x, landmark.y))    \n",
    "\n",
    "            detect_gesture(frame, list_landmarks, results)    \n",
    "\n",
    "            # show the frame\n",
    "            cv2.imshow('Camera Feed', frame)\n",
    "            # Exit on 'esc' key press\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a72e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the camera function to start the application\n",
    "camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fb2d2",
   "metadata": {},
   "source": [
    "# Thank You! ^^\n",
    "\n",
    "Terima kasih telah membaca hingga akhir \n",
    "Semoga proyek ini bisa menginspirasi dan membantu!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
